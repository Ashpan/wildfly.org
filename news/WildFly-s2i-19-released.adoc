= WildFly 19 S2I image has been released on quay.io
jfdenise
2020-03-20
:awestruct-tags: [wildfly, galleon]
:awestruct-layout: blog
:source-highlighter: coderay
:encoding: utf-8
:lang: en

==  WildFly 19 S2I docker images

WildFly s2i builder and runtime Docker images for WildFly 19 have been released on link:https://quay.io/organization/wildfly[quay.io/wildfly]

Changes since link:https://wildfly.org/news/2019/10/07/WildFly-s2i-18-released/[last release]:

* Optimized startup. The server starts much faster, the CLI script applied to the server configuration is now executed during server boot.
* Support for clustering. JGroups is now part of the default server configuration. 
* WildFly 19 Galleon decorator layer _web-clustering_ (support for Infinispan-based web session clustering) is fully usable in the openshift context. 
This blog post highlights the clustering new features.
* Default standalone.xml configuration file includes the Microprofile JWT (JSON Web Token) subsystem.
* WildFly 19 defined new Galleon layers for Microprofile 3.3 (_microprofile-fault-tolerance_, _microprofile-jwt_ and _microprofile-openapi_) can be referenced from 
_GALLEON_PROVISION_LAYERS_ env variable.

For a complete documentation on how to use these images using s2i, OpenShift and Docker, 
refer to link:https://github.com/wildfly/wildfly-s2i/blob/wf-19.0/README.md[README].

== Adding imagestreams and template to OpenShift

At some point the new images will be made available from OpenShift catalog and image repository. You can already use these images by adding them yourselves to your OpenShift cluster.

* WildFly S2I builder image stream: 
```
oc create -f https://raw.githubusercontent.com/wildfly/wildfly-s2i/wf-19.0/imagestreams/wildfly-centos7.json
```
* WildFly runtime image stream: 
```
oc create -f https://raw.githubusercontent.com/wildfly/wildfly-s2i/wf-19.0/imagestreams/wildfly-runtime-centos7.json
```
* Chained build template: 
```
oc create -f https://raw.githubusercontent.com/wildfly/wildfly-s2i/wf-19.0/templates/wildfly-s2i-chained-build-template.yml
```

NB: If you import the image streams in your project, be sure to set _ImageStreams Namespace_ to your project namespace in the template. _openshift_ being the default namespace.

== Clustering examples

=== Configure Openshift

* Allow to view all pods in the project: 
```
oc policy add-role-to-user view system:serviceaccount:$(oc project -q):default
```

* Be sure to kill any WildFly application running in the _myproject_ namespace. Any running application would join the cluster.


=== Web session sharing uging _web-clustering_ galleon layer

==== Build and run the application

We are provisioning a web server with support for web session sharing.

* Build application image: 
```
oc new-app wildfly-s2i-chained-build-template -p APPLICATION_NAME=web-clustering \
      -p GIT_REPO=https://github.com/wildfly/wildfly-s2i \
      -p GIT_CONTEXT_DIR=examples/web-clustering \
      -p GALLEON_PROVISION_LAYERS=web-server,web-clustering \
      -p IMAGE_STREAM_NAMESPACE=myproject
```

* Create application from application image: 

```
oc new-app myproject/web-clustering -e KUBERNETES_NAMESPACE=myproject -e JGROUPS_CLUSTER_PASSWORD=mypassword
```

NB: The KUBERNETES_NAMESPACE is required to see other pods in the project, otherwise the server attempts to retrieve pods from the 'default' namespace that is not the one our project is using.
JGROUPS_CLUSTER_PASSWORD is used to authenticate server in the cluster.

* Expose the service:
```
oc expose svc/web-clustering
```

* Access the application route, note the user created time and session ID.

* Scale the application to 2 pods: 
```
oc scale --replicas=2 dc web-clustering
```

* List pods: 
```
oc get pods
```

* Kill the oldest POD (that answered the first application request): 
```
oc delete pod web-clustering-1-r4cx8 -n myproject
```

* Access the application again, you will notice that the displayed values are the same, web session has been shared between the 2 pods.

=== Ejb singleton

Another aspect of the clustering feature is the support for ejb singleton. We are here running the _ha-singleton-deployment_ WildFly quickstart.
In this example we are using the default server present in the wildfly s2i builder image, we are not provisioning a server trimmed-down with Galleon. We don't have (yet) layers
for ejb features.

* Build application image: 
```
oc new-app wildfly-s2i-chained-build-template -p APPLICATION_NAME=singleton \
      -p GIT_REPO=https://github.com/wildfly/quickstart/ \
      -p GIT_BRANCH=19.0.0.Final \
      -p GIT_CONTEXT_DIR=ha-singleton-deployment  \
      -p IMAGE_STREAM_NAMESPACE=myproject \
      --build-env=MAVEN_ARGS_APPEND=-Dcom.redhat.xpaas.repo.jbossorg
```

* Create application from application image: 
```
oc new-app myproject/singleton -e KUBERNETES_NAMESPACE=myproject -e JGROUPS_CLUSTER_PASSWORD=mypassword
```

* Scale the application to 2 pods: 
```
oc scale --replicas=2 dc singleton
```

* Check the server logs: 
```
oc logs -f dc/singleton
```
One pod is elected for the timer service.

* List pods:
```
oc get pods
```

* Kill the oldest POD (elected one): 
```
oc delete pod singleton-1-r4cx8 -n myproject
```

The timer service is started in the remaining pod.

